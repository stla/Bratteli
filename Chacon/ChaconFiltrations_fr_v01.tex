\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[francais]{babel}
\usepackage[T1]{fontenc}
\usepackage{amsmath, amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{lmodern}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}

\usepackage{subcaption}
\usepackage{euscript}
\usepackage[toc,page]{appendix}
\usepackage{hyperref}
\usepackage{color}

\usepackage[all]{xy}

\author{Stéphane Laurent}
\title{Mots découpés à la Chacon}

\begin{document}

\newcommand{\BB}{\EuScript{B}}
\newcommand{\DD}{\EuScript{D}}
\newcommand{\FF}{\EuScript{F}}
\newcommand{\GG}{\EuScript{G}}
\newcommand{\HH}{\EuScript{H}}
\newcommand{\LL}{\EuScript{L}}
\renewcommand{\SS}{\EuScript{S}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\EE}{\mathbb{E}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\given}{\mid}
\newcommand{\indic}{\boldsymbol 1}
\newcommand{\indvee}{\dot{\vee}}
\newcommand{\tildepsilon}{\widetilde{\epsilon}}
\newcommand{\tildV}{\widetilde{V}}
\newcommand{\tildW}{\widetilde{W}}

\newcommand{\indep}{\mathrel{\text{\scalebox{1.07}{$\perp\mkern-10mu\perp$}}}}

\newtheoremstyle{thmstyle}{3pt}{3pt}{\itshape}{}{\bf}{.}{.5em}{}      
\newtheoremstyle{defstyle}{3pt}{3pt}{\sffamily}{}{\bf}{.}{.5em}{}       
\theoremstyle{thmstyle}
\newtheorem{thm}{Th\'eor\`eme}
\newtheorem{lemme}{Lemme}
\newtheorem{ppsition}{Proposition}
\theoremstyle{defstyle}
\newtheorem{definition}{D\'efinition}
\newtheorem{remarque}{Remarque}

\maketitle 


\tableofcontents

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction} 

Je vais démontrer que la filtration des mots découpés à la Chacon 
n'est pas standard lorsque les lettres des mots sont \emph{i.i.d.}. 
En termes savants (que seuls moi et Vershik utilisons) : le graphe de 
Chacon n'est pas dans l'échelle des automorphismes de Bernoulli. 

L'intérêt de ce travail réside dans l'utilisation du théorème~\ref{thm:joining}, 
qui n'est pas difficile mais qui est nouveau.  
La filtration des mots découpés à la Chacon est asymptotiquement triadique. 
Grâce à ce théorème, je vais déduire la non-standardité de cette filtration 
de la non-standardité de la filtration triadique des mots découpés. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{La filtration Chacon-adique élémentaire}

La figure de gauche ci-dessous permet de visualiser 
les trajectoires du processus de Chacon 
${(V_n, \epsilon_n)}_{n \leq 0}$.   
À chaque instant $n$, la variable aléatoire $V_n \in \{1,2\}$ est un sommet 
du graphe au niveau $n$, et la variable aléatoire $\epsilon_n \in \{0, 1, 2, 3\}$ 
est l'arc qui connecte $V_{n-1}$ et $V_n$. 

\begin{figure}[!h]
   \centering
   \begin{subfigure}[t]{0.47\textwidth}
   \centering
   	\includegraphics[scale=0.6]{figures/Chacon_Labels_hand}
 		\caption{\footnotesize Graphe de Chacon}\label{fig:ChaconLabels}
    \end{subfigure}              
   \quad
    \begin{subfigure}[t]{0.47\textwidth}
    \centering
   	\includegraphics[scale=0.6]{figures/Chacon_DimsProbs_hand}
 		\caption{\footnotesize Dimensions et probabilités de transitions}\label{fig:ChaconDimsProbs}
 	\end{subfigure}      

   \caption{Filtration de Chacon}\label{fig:ChaconGraph}
   \label{fig:ostro}
 \end{figure}

Sur la figure de droite, la \emph{dimension} de chaque sommet est indiquée à la place 
du sommet correspondant. C'est le nombre de chemins qui relient ce sommet à la racine 
de l'arbre. Elle est toujours égale à $1$ pour les sommets situés à droite. 
Notons $d_n$ la dimension du sommet situé à gauche au niveau $n$. 
Elle est donnée récursivement par $d_0=4$ et $d_{n-1} = 3 \times d_n+1$. 
On a alors $d_n=\frac{3^{-n+2}-1}{2}$. Cette formule est encore 
valable au niveau de la racine si on considère que c'est le niveau $n=1$. 

La loi du processus ${(V_n, \epsilon_n)}_{n \leq 0}$ est définie par :

\begin{itemize}
\item[$\bullet$] $V_n = 2$ avec probabilité $1/3^{|n|+1}$ ;

\item[$\bullet$] $\epsilon_n=0$ et $V_n=2$ si $V_{n-1}=2$ ;

\item[$\bullet$] conditionnellement à $V_{n-1}=1$, l'arc $\epsilon_n$ prend la 
valeur $2$ avec probabilité $1/d_{n}$, et prend une valeur dans 
$\{0,1,3\}$ avec probabilité $d_{n+1}/d_n$. 
\end{itemize}

Le choix des étiquettes sur les arcs sera justifié plus tard.

Nous notons $\FF$ la filtration engendrée par ${(V_n, \epsilon_n)}_{n \leq 0}$. 
C'est une filtration "conditionnellement poly-adique" :  
conditionnellement à $\FF_n$, le chemin $(\epsilon_{n+1}, \ldots, \epsilon_0)$ 
est uniforme sur les $\dim(V_n)$ chemins possibles. 
En d'autres termes, le chemin infini correspondant à la trajectoire 
de ${(V_n, \epsilon_n)}_{n \leq 0}$ est pioché au hasard selon une \emph{mesure centrale}. 

Il y a maintes façons de démontrer que $\FF$ est standard :

\begin{enumerate}
\item Suivant une remarque dans \cite{JLR}, la standardité de $\FF$ est équivalente 
à celle du processus ${(V_n)}_{n \leq 0}$. C'est une chaîne de Markov monotone, 
 et sa filtration est standard d'après un théorème de \cite{JLR}. 
 Plus précisément, on obtient l'existence d'une paramétrisation 
 génératrice de $\FF$ en utilisant les résultats de \cite{JLR}.
 
\item Il est plus simple de construire une paramétrisation génératrice à la main. 
En fait, toute paramétrisation est génératrice. 
Naturellement, on prend $U_n$ indépendante de $\FF_{n-1}$, uniforme sur 
$d_n = 3d_{n+1} +1$ valeurs,  
on partitionne ces $d_n$ valeurs en trois blocs $B_0$, $B_1$ et $B_3$ de $d_{n+1}$ valeurs 
et un bloc $B_2$ de une valeur, puis on définit $\epsilon_n$ quand $V_{n-1}=1$ 
comme étant l'indice $i$ du bloc $B_i$ dans lequel est $U_n$. 
L'événement $\{V_{n_0}=1\}$ a une probabilité aussi proche de $1$ qu'on le souhaite quand 
${n_0} \to -\infty$, et sur cet événement, $(V_{n_0+1}, \ldots, V_0)$ est 
déterminé par les $U_n$. 
 
\item Le $I$-confort de $\FF$ s'établit facilement du fait que 
l'événement $\{V_{n_0}=1\}$ a une probabilité aussi proche de $1$ qu'on le souhaite quand 
${n_0} \to -\infty$. 

\item Enfin, on peut s'amuser à utiliser le critère de Vershik. 
Suivant la remarque de \cite{JLR}, la standardité de $\FF$ est équivalente 
à celle du processus ${(V_n)}_{n \leq 0}$. La variable aléatoire $\pi_n V_0$ 
engendre la même tribu que $V_n$, et il suffit alors de vérifier le critère 
de Vershik pour $V_0$. Il n'est même pas nécessaire de calculer 
les distances de Kantorovich, puisque $V_n=1$ avec probabilité qui tend vers 
$1$, donc la dispersion de $V_n$ tend évidemment vers $0$. 
Pour information, on obtient la distance de Kantorovich 
$\rho_n(1,2)=3^{|n|}/d_n \to 2/3$. 
\end{enumerate}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Couplage de $(V_n,\epsilon_n)$ et $(\tildV_n, \widetilde{\epsilon}_n)$}

Nous donnons ici une autre preuve de la standardité de $\FF$. 
Mais ce n'est pas le but de cette section : 
les outils introduits ici seront utilisés plus tard.  
Il s'agit de formaliser et d'utiliser le fait que $\FF$ est asymptotiquement 
triadique. 
Nous allons d'abord montrer que le processus ${(V_n, \epsilon_n)}_{n \leq 0}$ 
est \emph{bien couplable}\footnote{devrais-je dire \emph{asymptotiquement bien couplable ?}} 
avec un processus engendrant une filtration triadique, 
au sens suivant.

\begin{definition}
Deux processus  ${(X_n)}_{n \leq 0}$ et ${(Y_n)}_{n \leq 0}$ sont \emph{bien couplables}  
si pour tout $n_0 \leq 0$ il existe un couplage de 
${(X_n)}_{n_0 \leq n \leq 0}$ et ${(Y_n)}_{n_0 \leq n \leq 0}$ tel que :
\begin{enumerate}
\item ${(X_n)}_{n_0 \leq n \leq 0}$ et ${(Y_n)}_{n_0 \leq n \leq 0}$ 
sont co\"immergés ; 

\item  pour tout $\delta >0$, il existe $N_\delta \leq 0$ tel que   
$$
\Pr(X_{n_0}=Y_{n_0}, \ldots, X_{N_\delta}=Y_{N_\delta}) > 1-\delta 
$$
quand $n_0$ est suffisamment plus petit que $N_\delta$.
\end{enumerate} 
\end{definition}

\begin{remarque}
Je me restreinds à la distance discrète ($X_n=Y_n$) pour une raison qui sera 
dite un peu plus tard.
\end{remarque}

Soit ${(\widetilde{\epsilon}_n)}_{n \leq 0}$ une suite de v.a. indépendantes 
et uniformes sur $\{0,1,3\}$. 
 Prenons aussi une variable aléatoire $\widetilde{V}_n$ égale à $1$ 
presque sûrement pour tout $n \leq 0$. Ça peut sembler inutile mais 
cela rendra les notations plus propres. 

\begin{lemme}\label{lemme:joining_epsilon}
Les processus 
${(V_n, \epsilon_n)}_{n \leq 0}$ et 
 ${(\tildV_n, \widetilde{\epsilon}_n)}_{n \leq 0}$ sont bien couplables. 
\end{lemme}

\begin{proof}
Pour $i \in \{0,1,3\}$, 
$$
\Pr(V_n=1, \epsilon_n=i) = \frac{3^{|n|+1}-1}{3^{|n|+2}} < \frac{1}{3}.
$$
On peut alors construire un couplage de 
$(V_{n_0}, \epsilon_{n_0})$ et $(\tildV_{n_0},\tildepsilon_{n_0})$ telle que 
$$
\{V_{n_0}=1, \epsilon_{n_0}=i\} \subset \{\tildV_{n_0}=1,\tildepsilon_{n_0} = i\} 
$$
pour $i \in \{0,1,3\}$. 

On construit ${(V_n, \epsilon_n)}_{n_0 \leq n \leq 0}$ récursivement. 
Quand la construction est faite jusqu'au temps $n$, 
on pose $\epsilon_{n+1} = f_n(V_n, U_{n+1})$ où 
$U_{n+1}$ est une v.a.\ uniforme sur $[0,1]$ indépendante du processus jusqu'à 
l'instant $n$. Pour $i \in \{0,1,3\}$, la fonction $f_n$ est telle que 
$f_n(1, u) = i$ lorsque $u \in J_i$ où  $|J_i| = \frac{d_{n+2}}{d_{n+1}} < \frac{1}{3}$. 
On peut alors construire $J'_i \supset J_i$ tel que $|J'_i|=\frac{1}{3}$ et 
poser $\tildepsilon_{n+1}=i$ lorsque $u \in J'_i$. 
Ainsi, sur l'événement $\{V_n=1\}$ on a $\tildepsilon_{n+1}=i$ si $\epsilon_{n+1}=i$. 

Avec cette construction on a alors 
$$
\Pr\bigl((V_{n_0+1}, \epsilon_{n_0+1})=(\widetilde{V}_{n_0+1}, \widetilde{\epsilon}_{n_0+1}), 
\ldots, (V_N, \epsilon_{N})=(\widetilde{V}_{N},\widetilde{\epsilon}_{N}) 
\given V_{n_0}=1 \bigr) \geq \prod_{n=n_0+1}^N \frac{d_{n+1}}{d_{n}}.  
$$
Le lemme s'ensuit du fait que le  produit $\prod_{n=n_0+1}^N \frac{d_{n+1}}{d_{n}}$ diverge lorsque $n_0 \to -\infty$, 
et $\Pr(V_{n_0}=1) \to 1$. 
%La loi de $\epsilon_n$ conditionnelle à $V_{n-1}=1$ est distribuée sur $\{0, 1, 2, 3\}$ 
%selon le vecteur de probabilité
%$$
%\left(\frac{d_{n+1}}{d_n}, \frac{d_{n+1}}{d_n}, \frac{1}{d_n}, \frac{d_{n+1}}{d_n} \right)
%$$
\end{proof}


%%%%%%%%%%%%%%%

%Donnons une autre méthode. Ce n'est pas pour s'amuser : elle sera utilisée plus tard. 
%Il s'agit de formaliser et d'utiliser le fait que $\FF$ est asymptotiquement 
%triadique. 
%
%Soit ${(\widetilde{\epsilon}_n)}_{n \leq 0}$ une suite de v.a. indépendantes 
%et uniformes sur $\{0,1,3\}$. Notons aussi $\widetilde{V}_n$ une v.a. égale à $1$ 
%presque sûrement. 
%
%Il est possible de coupler ${(\widetilde{V}_n, \widetilde{\epsilon}_n)}_{n \leq 0}$ 
%avec ${(V_n, \epsilon_n)}_{n \leq 0}$ de façon coïmmergée et de sorte que : 
%{\it Pour tout $\delta >0$, il existe $N \leq 0$ tel que pour tout $n_0 \leq N$,}
%$$
%\Pr\bigl((V_{n_0}, \epsilon_{n_0})=(\widetilde{V}_{n_0}, \widetilde{\epsilon}_{n_0}), (V_{n_0+1}, \epsilon_{n_0+1})=(\widetilde{V}_{n_0+1},\widetilde{\epsilon}_{n_0+1}), \ldots, (V_N, \epsilon_{N})=(\widetilde{V}_{N},\widetilde{\epsilon}_{N})\bigr) > 1-\delta. 
%$$ 
%
%Je préciserai les hypothèses générales du théorème ci-dessous dans une version ultérieure. 

\begin{thm}\label{thm:joining}
Soient ${(X_n)}_{n \leq 0}$ et ${(Y_n)}_{n \leq 0}$ deux processus couplables 
telles que les v.a.\ $X_n$ et $Y_n$ prennent un nombre fini de valeurs. 
Alors la filtration de l'un est I-confortable si et seulement si 
la filtration de l'autre est I-confortable.
\end{thm} 

À noter cet aspect intéressant du I-confort : 
je ne sais pas démontrer ça avec le critère de Vershik à la place du I-confort. 

Je parierais que sous les hypothèses de ce théorème, les entropies des deux 
filtrations sont les mêmes, mais que pour démontrer cela il faudrait formuler l'entropie en 
termes de couplages. Ceci montre l'intérêt de développer cette formulation 
de l'entropie même si elle ne permettrait pas de calculer l'entropie sur des exemples.

Aussi : sous les conditions du théorème, une filtration est kolmogorovienne si et seulement 
si l'autre l'est. 

Passons à la preuve du théorème.

%\begin{lemme}
%Soit ${(W_n, \epsilon_n)}_{n \leq 0}$ un processus. 
%On note $GG$ sa filtration. 
%On suppose que $\GG_{n+1} = \GG_n \vee \sigma(\epsilon_{n+1})$ 
%et que $\epsilon_{n+1}$ est conditionnellement indépendante de 
%$\GG_n$ sachant $\epsilon_n$. 
%Alors il existe une paramétrisation de 
% ça chie pour Pascal
%\end{lemme}


\begin{proof}[Preuve du théorème~\ref{thm:joining}]
Notons $\FF$ la filtration de  ${(X_n)}_{n \leq 0}$ et 
$\GG$ celle de ${(Y_n)}_{n \leq 0}$
Supposons que $\FF$ est I-confortable.
Nous prenons un entier $N \leq 0$ et démontrons le I-confort de 
$(Y_N, \ldots, Y_0)$.  
Soient $\delta >0$ et $N_\delta$ l'entier donné par les hypothèse. 
On peut supposer $N_\delta \leq N$. 

La variable aléatoire $X_{N_\delta}$ satisfait le critère de I-confort. 
On a donc deux copies ${(X'_n)}_{n \leq N_\delta}$ et ${(X''_n)}_{n \leq N_\delta}$ 
indépendantes jusqu'à $n_0$ et telles que $\Pr(X'_{N_\delta} \neq X''_{N_\delta}) < \delta$. 
Par le lemme~\ref{lemme:quadricoimm}, on peut étendre ceci 
en deux copies  ${(X'_n, Y'_n)}_{n \leq N_\delta}$ et ${(X''_n, Y''_n)}_{n \leq N_\delta}$ 
du couplage donné par les hypothèses. 
On a donc  deux copies ${(Y'_n)}_{n \leq N_\delta}$ et ${(Y''_n)}_{n \leq N_\delta}$ 
de ${(Y_n)}_{n \leq N_\delta}$ coïmmergées et indépendantes jusqu'à $n_0$, 
et on a $\Pr(Y'_{N_\delta} \neq Y''_{N_\delta}) < 3\delta$ 
quand $n_0$ est suffisamment plus petit que $N_\delta$. 
Pour finir, on prolonge ce couplage de sorte que 
$\{Y'_n = Y''_n\} \subset \{Y'_{n+1} = Y''_{n+1}\}$.
\end{proof}

\begin{remarque}
Voilà la raison pour laquelle j'ai supposé que $Y_n$ ne prend qu'un nombre fini de 
valeurs. Cela permet, lorsqu'on a un couplage jusque $n=N_\delta$ tel que 
$\Pr(Y'_{N_\delta} \neq Y''_{N_\delta}) < 3\delta$, de le prolonger jusqu'à 
$n=0$ en conservant cette prochitude. Il faudrait \^etre un peu plus technique 
si on veut ce théorème pour des v.a.\ dans un espace métrique. 
\end{remarque}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Filtration Chacon-adique de mots découpés}

Soit $T$ une transformation inversible d'un espace de Lebesgue $(X,\nu)$, 
préservant la mesure de probabilité $\nu$. 

\subsection{Le processus $(Z_n,\epsilon_n)$}

Prenons une variable aléatoire $Z_0 \sim \nu$ indépendante de $\FF_0$. 
On pose 
$$
Z_n = T^{-K_n}Z_0
$$
où $K_n=\sum_{k=0}^{n+1}f_k(\epsilon_k)$, la fonction $f_n$ étant définie par 
$$
\begin{cases}
f_n(0) = 0 \\ 
f_n(1) = d_{n+1} \\ 
f_n(2) = 2d_{n+1} \\
f_n(3) = 2 d_{n+1} + 1
\end{cases}.
$$
En particulier, $f_0(j)=j$ (rappelons qu'on pose $d_1=1$). 

La figure ci-dessous montre la structure du processus ${(Z_n, \epsilon_n)}_{n \leq 0}$. 
Une case rouge indique $V_n=2$. 
On note $\GG$ la filtration de ce processus. La filtration $\FF$ est immergée dans $\GG$. 

La loi de ${(Z_n, \epsilon_n)}_{n \leq 0}$ est définie par : 
\begin{itemize}
\item[$\bullet$] $Z_n \sim \nu$ est indépendante de $\epsilon_n$ ;

\item[$\bullet$] si $V_n=2$, $Z_{n+1} = Z_n$ 

\item[$\bullet$] conditionnellement à $\GG_n$, sur l'événement $\{V_n=1\}$, 
on a $Z_{n+1} = T^k Z_n$ où $k=\epsilon_{n+1} d_{n+1}$ si $\epsilon_{n+1} \in \{0, 1, 2\}$, 
et $k = 2 d_{n+1} + 1$ si $\epsilon_{n+1}=3$. 
\end{itemize}

\begin{figure}[!h]
\centering
	\includegraphics[scale=0.8]{figures/ChaconWalk_powers_N2_hand}
\caption{Le processus $(Z_n, \epsilon_n)$}\label{fig:Zn}
\end{figure}

Ainsi la filtration $\GG$ est localement isomorphe à $\FF$. 
Sa tribu germe $\GG_{-\infty}$ est donnée par mes réflexions 
sur la généralisation de l'échelle d'un automorphisme. 
On a la proposition suivante qui est une application d'un fait général : 

\begin{ppsition}
La tribu germe $\GG_{-\infty}$ est triviale si et seulement si $T\times S$ est ergodique, 
où $S$ est la transformation de Chacon. 
\end{ppsition}

%D'après les ergodiciens,  $T\times S$ est ergodique si et seulement si 
%$T$ est ergodique et si $T$ et $S$ n'ont pas de valeur propre commune. 
%La transformation de Chacon est connue pour être faiblement mélangeante 
%et elle donc pas de valeur propre n'a pas de valeur propre. Donc $T\times S$ est ergodique si 
%et seulement si $T$ est ergodique. 
La transformation de Chacon est connue pour être faiblement mélangeante,  
et il y a équivalence entre \og $S$ faiblement mélangeante \fg{} et 
\og $T\times S$ egodique pour toute $T$ ergodique \fg. 
Donc $\GG$ est kolmogorovienne pour toute transformation ergodique $T$. 

\medskip 

{\scriptsize %%%%%%
Il est donc temps d'introduire la transformation de Chacon. 
Cela expliquera d'où vient cette définition de $Z_n$, ainsi que le choix 
des étiquettes sur les arcs du graphe. 

Le graphe de la figure~\ref{fig:ChaconLabels} correspond à un découpage-empilage. 
La première étape est représentée sur la figure \ref{fig:scan} ci-dessous.
Il y a plus de détails sur le découpage-empilage dans l'appendice~\ref{app:transfoChacon} et 
le document auquel cette appendice fait référence.

\begin{figure}[!h]
\centering
	\includegraphics[scale=0.1]{figures/Chacon_CutAndStack_scan.png}
\caption{Le premier découpage-empilage}\label{fig:scan}
\end{figure}

Ce découpage-empilage définit la suite décroissante de partitions mesurables 
correspondant à la filtration $\FF$. 
À l'étape $n=0$, un point $x \in (0,1)$ est tiré au hasard, selon une loi uniforme. 
La partition mesurable $\xi_0$ est l'ensemble des singletons de $(0,1)$. 
À l'étape $n=-1$, le point $x$ se retrouve dans l'un des étages de la tour. 
S'il est dans la tour de gauche, on ne le voit plus : on voit 
seulement les $4$ points comme sur la figure. Ces $4$ points sont la classe 
d'équivalence-$\xi_{-1}$ de $x$.  

Il y a deux versions de la transformation de Chacon $S$ :
\begin{enumerate}
\item Sur $(0,1)$, elle envoie un point $x$ sur le point à l'étage au-dessus. 
Si $x$ est dans l'étage du haut, il faut aller regarder dans une tour plus grande 
pour déterminer $Sx$. 

\item Sur le graphe de la  figure~\ref{fig:ChaconLabels}, c'est la transformation adique. 
On la visualise facilement sur la figure~\ref{fig:Zn} : elle envoie une branche 
de l'arbre à la branche juste à côté à droite. Si on est à la dernière branche, 
il faut dessiner l'arbre à partir du niveau $n$ précédent pour déterminer la 
branche suivante. 
\end{enumerate}

Voilà alors d'où sort l'entier aléatoire 
$K_n=\sum_{k=0}^{n+1}f_k(\epsilon_k)$ : 
Cet entier indique dans quel étage de la tour au niveau $n$ se situe 
le point $x$ tiré au hasard. 
}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Mots découpés chacon-adiques}

Prenons une partition finie de $X$, étiquetée par des lettres $a$, $b$, $\ldots$.  
On note $W_n(i)$ l'étiquette du point $T^iZ_n$, pour $i$ allant de 
$0$ à $d_n-1$ si $V_n=1$, sinon juste pour $i=0$. 
On crée ainsi un processus de mots découpés ${(W_n, \epsilon_n)}_{n \leq 0}$, 
que la figure suivante permet de visualiser :

\begin{figure}[!h]
\centering
	\includegraphics[scale=0.8]{figures/ChaconWalk_words_hand}
\caption{Le processus $(W_n, \epsilon_n)$}\label{fig:Wn}
\end{figure}

La filtration engendrée par le processus $(W_n, \epsilon_n)$ est immergée dans 
$\GG$. 
Si $P$ est une partition génératrice de $T$, cette filtration est 
 $\GG$.  


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{I-confort de $\GG$}


Nous allons utiliser le théorème~\ref{thm:joining}. 
Définissons le processus  ${(\widetilde{W}_n, \widetilde{\epsilon}_n)}_{n \leq 0}$ suivant. 
Le processus ${(\widetilde{\epsilon}_n)}_{n \leq 0}$ est celui introduit 
avant le théorème~\ref{thm:joining}. 
Le processus  ${(\widetilde{W}_n, \widetilde{\epsilon}_n)}_{n \leq 0}$ 
est alors défini de façon analogue à ${(W_n, \epsilon_n)}_{n \leq 0}$ 
en remplaçant $\epsilon_n$ par $\widetilde{\epsilon}_n$ : 
$\widetilde{W}_n$ a même loi que $W_n$, et $\widetilde{W}_{n+1}$ est un 
des trois sous-mots de longueur $d_{n+1}$ de $\widetilde{W}_n$, sélectionné par 
$\widetilde{\epsilon}_n$. 

Autrement dit, ce processus se visualise aussi sur la figure~\ref{fig:Wn}, 
la différence étant qu'on ne sélectionne jamais une case rouge. 
Sur la figure~\ref{fig:tildeWn}, nous utilisons deux couleurs pour être plus clair.


\begin{figure}[!h]
\centering
	\includegraphics[scale=0.8]{figures/ChaconWalk_words_tilde}
\caption{Le processus $(\widetilde{W}_n, \widetilde{\epsilon}_n)$}\label{fig:tildeWn}
\end{figure}

\begin{lemme}
Les processus ${(W_n, \epsilon_n)}_{n \leq 0}$ et 
${(\widetilde{W}_n, \widetilde{\epsilon}_n)}_{n \leq 0}$ 
vérifient les hypothèses du théorème~\ref{thm:joining}. 
\end{lemme}

\begin{proof}
On utilise le couplage du lemme~\ref{lemme:joining_epsilon}. 
Pour construire le couplage désiré, on commence par construire $W_{n_0} = f(V_{n_0}, U)$ 
où $U$ est une v.a.\ indépendante de $V_{n_0}$. 
Puis on construit $W_n$ sur $n_0 < n \leq 0$ avec les $\epsilon_n$. 
On pose $\tildW_{n_0} = f(\tildV_{n_0}, U)$ et, de même, on 
 construit $\tildW_n$ sur $n_0 < n \leq 0$ avec les $\tildepsilon_n$. 
\end{proof}

\begin{lemme}
Soit $\widetilde{X}_n$ le mot $\widetilde{W}_n$ privé de ses lettres en couleur $(\widetilde{X}_0=\widetilde{W}_0)$. 
Alors le processus $(\widetilde{X}_n, \widetilde{\epsilon}_n)$ est un mots-découpés triadique, 
et la filtration qu'il engendre est immergée dans $\widetilde{\GG}$.
\end{lemme}

Quand $T$ est le décalage de Bernoulli et $W_n$ est obtenu avec la partition 
selon la coordonnée centrale, les lettres de $W_n$ sont \emph{i.i.d.} sur un alphabet 
fini. Il en est de même des lettres de $\widetilde{X}_n$. 
Dans ce cas, on déduit des deux lemmes précédents, du théorème~\ref{thm:joining}, 
et de notre connaissance sur le cas triadique, que $\GG$ n'est pas standard. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Questions et remarques} 

\begin{enumerate}
\item \`A part le cas du décalage de Bernoulli, on ne trouve pas des lettres 
stationnaires pour $\widetilde{X}_n$. 

\item Si l'entropie de $T$ n'est pas nulle, alors $T$ admet un facteur 
de Bernoulli d'après le théoème de Sinai, donc $\GG$ n'est pas standard. 

\item Si l'entropie de a transformation $T$ est nulle alors l'entropie exponentielle de la 
filtration de $(\widetilde{X}_n, \widetilde{\epsilon}_n)$ est nulle aussi. 
En effet $\frac{H(\widetilde{X}_n)}{3^n} \leq \frac{H(\widetilde{W}_n)}{3^n} = \frac{d_n}{3^n}\frac{H(\widetilde{W}_n)}{d_n} \sim 3h(T)$.

\item Si mes idées à propos de la définition généralisée de l'échelle sont correctes, 
on devrait trouver que $\GG$ est standard lorsque $T$ est elle-même la transformation de 
Chacon, puisque $\FF$ est standard. Je ne sais pas le démontrer. 

\item $\GG$ est-elle isomorphe à $\FF$ lorsqu'elle est standard ? 
\end{enumerate}

\newpage 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{appendices}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Transformation de Chacon}\label{app:transfoChacon}

La figure ci-dessous est issue de \href{https://cdr.lib.unc.edu/indexablecontent/uuid:bfc41b0c-b048-440f-9a57-533e02ea4f76}{ce document}.  

\begin{figure}[!h]
\includegraphics[scale=1]{figures/Chacon_CutAndStack_screenshot.png} 
\caption{Découpage-empilage à la 1ère étape}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Assemblage de co\"immersions}
%
%\begin{lemme}\label{lemme:coimmersion}
%Soit ${(X_n, Y_n)}_{n_0 \leq n \leq 0}$. 
%On a deux copies ${(X'_n)}_{n_0 \leq n \leq 0}$ et ${(X''_n)}_{n_0 \leq n \leq 0}$ 
%coïmmergées de ${(X_n)}_{n_0 \leq n \leq 0}$. 
%
%Alors on peut les prolonger en deux copies  ${(X'_n, Y'_n)}_{n_0 \leq n \leq 0}$ et 
%${(X''_n, Y''_n)}_{n_0 \leq n \leq 0}$ 
%coïmmergées de ${(X_n, Y_n)}_{n_0 \leq n \leq 0}$. 
%\end{lemme}
%
%\begin{proof}
%On peut écrire $Y_{n_0} = f(X_{n_0}, V_{n_0})$ où $V_{n_0} \indep X_{n_0}$. 
%Puis on peut écrire $Y_{n_0+1} = f\bigl((X_{n_0}, Y_{n_0}, X_{n_0+1}), V_{n_0+1}\bigr)$ où 
%$V_{n_0+1} \indep (X_{n_0}, V_{n_0}, X_{n_0+1})$, etc. 
%
%On prend alors $V'_{n_0} \indep (X'_{n_0}, \FF''_0)$ et on pose 
% $Y'_{n_0} = f(X'_{n_0}, V'_{n_0})$. 
% 
% Puis on prend $V'_{n_0+1} \indep (X'_{n_0}, V'_{n_0}, X'_{n_0+1}, \FF''_0)$ 
% puis on pose $Y'_{n_0+1} = f\bigl((X'_{n_0}, Y'_{n_0}, X'_{n_0+1}), V'_{n_0+1}\bigr)$. 
%
%
%\begin{displaymath}
%\xymatrix{
%Y'_{n_0} & Y'_{n_0+1} \\
%X'_{n_0} \ar[u]_{V'_{n_0}} & X'_{n_0+1} \ar[u]_{V'_{n_0+1}}  \\
%X''_{n_0} \ar[d]^{V''_{n_0}} & X''_{n_0+1} \ar[d]^{V''_{n_0+1}} \\
%Y''_{n_0} & Y''_{n_0+1}
%}
%\end{displaymath}
%
%\end{proof}
%
%\newpage 
%
%J'ai : 
%
%\begin{itemize}
%\item une coïmmersion de $(\epsilon_0, \epsilon_1)$ et $(\eta_0, \eta_1)$ :
%%$$
%%\begin{matrix}
%%\eta_0 & \eta_1 \\
%%\epsilon_0 & \epsilon_1
%%\end{matrix}
%%$$
%%$$
%%\begin{pmatrix}
%%\eta_0 \\
%%\epsilon_0
%%\end{pmatrix},
%%\begin{pmatrix}
%%\eta_1 \\
%%\epsilon_1
%%\end{pmatrix}
%%$$
%$$
%\begin{matrix}
%(\eta_0, \eta_1) \\
%(\epsilon_0,  \epsilon_1)
%\end{matrix}
%$$
%
%\item une coïmmersion de $(\epsilon'_0, \epsilon'_1)$ et $(\epsilon''_0, \epsilon''_1)$ :
%$$
%\begin{matrix}
%(\epsilon'_0, \epsilon'_1) \\
%(\epsilon''_0,  \epsilon''_1)
%\end{matrix}
%$$
%\item Il faut construire
%$$
%\begin{matrix}
%\eta'_0 & \eta'_1 \\
%\epsilon'_0 & \epsilon'_1 \\
%\epsilon''_0 &  \epsilon''_1 \\
%\eta''_0 & \eta''_1
%\end{matrix}.
%$$
%\end{itemize}
%
%On part du 2ème couplage et on va le grossir. 
%
%Il n'est pas difficile de construire la première colonne :
%\begin{displaymath}
%\xymatrix @R=.5pc{
%\eta'_0  \\ \\
%\epsilon'_0  \ar@/^.6pc/[uu]^{U'_0}   \\
%\epsilon''_0  \ar@/^-.6pc/[dd]_{U''_0}\\ \\
%\eta''_0
%}
%\end{displaymath}
%Ce dessin signifie qu'on prend une v.a.\ $U_0$ telle que $\eta_0=f(\epsilon_0,U_0)$, on prend deux copies indépendantes $U'_0$ et $U''_0$ et on pose $\eta'_0=f(\epsilon'_0,U'_0)$ 
%et $\eta''_0=f(\epsilon''_0,U''_0)$.
%
%Ensuite j'ai envie de faire ça :
%\begin{displaymath}
%\xymatrix @R=.5pc{
%\eta'_0  & \eta'_1 \\ \\
%\epsilon'_0  \ar@/^.6pc/[uu]^{U'_0} & \epsilon'_1  \ar@/^.6pc/[uu]^{U'_1}  \\
%\epsilon''_0  \ar@/^-.6pc/[dd]_{U''_0} & \epsilon''_1  \ar@/^-.6pc/[dd]_{U''_1}  \\ \\
%\eta''_0 & \eta''_1
%}
%\end{displaymath}
%Ici on a pris $U_1$ telle que $\eta_1 = f(\epsilon_0, \eta_0, \epsilon_1,U_1)$. 
%Il est clair que comme ça on respecte la loi du premier couplage. 
%
%Mais il reste à voir que les copies de $(\eta_0, \eta_1)$ sont co\"immergées. 
%C'est OK si :
%$$
%\Pr(\eta'_1 \in \cdot \given \text{1ère colonne}) \overset{\boldsymbol ?}{=} \Pr(\eta'_1 \in \cdot \given \epsilon'_0, \eta'_0)
%$$
%On a 
%$$ 
%\Pr(\eta'_1 \in \cdot \given \text{1ère colonne}, \epsilon'_1) =  
%\Pr\bigl(\eta'_1 \in \cdot \given (\epsilon'_0, \eta'_0), \epsilon'_1\bigr),
%$$
%et on a alors 
%$$ 
%\Pr(\eta'_1 \in \cdot \given \text{1ère colonne}) =  
%\Pr\bigl(\eta'_1 \in \cdot \given (\epsilon'_0, \eta'_0)\bigr)
%$$
%à condition que 
%${\cal L}(\epsilon'_1 \given \text{1ère colonne}) = 
% {\cal L}(\epsilon'_1 \given \epsilon'_0)$, et ceci m'a l'air bon 
% car on a pris $U'_0$ et $U''_0$ indépendantes du 2ème couplage. 
%
%
%%%%%%%%
%\newpage 

%\begin{lemme}
%Soient ${(X_n)}_{0 \leq n \leq n_0}$ et ${(Y_n)}_{0 \leq n \leq n_0}$ 
%deux vecteurs aléatoires synchroniquement couplés. 
%Sur un autre espace probabilisé, soient ${(X'_n)}_{0 \leq n \leq n_0}$ 
%et ${(X''_n)}_{0 \leq n \leq n_0}$ deux copies synchroniquement couplées 
%de ${(X_n)}_{0 \leq n \leq n_0}$. 
%Alors, sur cet espace probabilisé éventuellement grossi, il 
%existe deux copies  ${(Y'_n)}_{0 \leq n \leq n_0}$  et 
%${(Y''_n)}_{0 \leq n \leq n_0}$ de ${(Y_n)}_{0 \leq n \leq n_0}$ 
%de ${(Y_n)}_{0 \leq n \leq n_0}$ 
%synchroniquement couplées et 
%telles que $\bigl\{{(X'_n)}_{0 \leq n \leq n_0}, {(Y'_n)}_{0 \leq n \leq n_0}\bigr\}$ 
%et $\bigl\{{(X''_n)}_{0 \leq n \leq n_0}, {(Y''_n)}_{0 \leq n \leq n_0}\bigr\}$ 
%sont deux copies de $\bigl\{{(X_n)}_{0 \leq n \leq n_0}, {(Y_n)}_{0 \leq n \leq n_0}\bigr\}$.
%\end{lemme}

Lorsque deux  vecteurs aléatoires ${(X_n)}_{0 \leq n \leq n_0}$ et ${(Y_n)}_{0 \leq n \leq n_0}$ 
engendrent des filtrations co\"immergées, j'écris ici que 
$\left\{\begin{smallmatrix} {(X_n)}_{0 \leq n \leq n_0} \\ 
{(Y_n)}_{0 \leq n \leq n_0}
\end{smallmatrix}\right.$  
est un \emph{couplage synchrone} de 
${(X_n)}_{0 \leq n \leq n_0}$ et ${(Y_n)}_{0 \leq n \leq n_0}$. 
La notation verticale permet d'alléger le texte. 

J'écris plusieurs fois \og{\it on a clairement}\fg{} dans la preuve du lemme ci-dessous. 
En fait, quand je dis ça, j'utilise à chaque fois un des deux faits suivants :
\begin{itemize}
\item si $U \indep {\cal B} \subset {\cal A}$, 
alors une v.a.\ $X$ mesurable pour $\sigma({\cal B}, U)$ est conditionnellement 
indépendante de ${\cal A}$ sachant ${\cal B}$ ;

\item si $U \indep \sigma({\cal B}, X)$ alors $X$ est  conditionnellement 
indépendante de $\sigma({\cal B}, U)$ sachant ${\cal B}$.  
\end{itemize}

\begin{lemme}\label{lemme:quadricoimm}
Soient 
$\left\{\begin{smallmatrix} {(X_n)}_{0 \leq n \leq n_0} \\ 
{(Y_n)}_{0 \leq n \leq n_0}
\end{smallmatrix}\right.$  
un couplage synchrone de 
deux vecteurs aléatoires ${(X_n)}_{0 \leq n \leq n_0}$ et ${(Y_n)}_{0 \leq n \leq n_0}$. 
Sur un autre espace probabilisé, soit 
$\left\{\begin{smallmatrix} {(X'_n)}_{0 \leq n \leq n_0} \\ 
{(X''_n)}_{0 \leq n \leq n_0}
\end{smallmatrix}\right.$
un couplage synchrone de deux copies 
de ${(X_n)}_{0 \leq n \leq n_0}$. 
Alors, sur cet espace probabilisé éventuellement grossi, il 
existe un couplage synchrone 
$\left\{\begin{smallmatrix} {(Y'_n)}_{0 \leq n \leq n_0} \\ 
{(Y''_n)}_{0 \leq n \leq n_0}
\end{smallmatrix}\right.$
de deux copies de ${(Y_n)}_{0 \leq n \leq n_0}$ 
 tel que 
$\left\{\begin{smallmatrix} {(X'_n)}_{0 \leq n \leq n_0} \\ 
{(Y'_n)}_{0 \leq n \leq n_0}
\end{smallmatrix}\right.$ et
$\left\{\begin{smallmatrix} {(X''_n)}_{0 \leq n \leq n_0} \\ 
{(Y''_n)}_{0 \leq n \leq n_0}
\end{smallmatrix}\right.$
sont deux copies de 
$\left\{\begin{smallmatrix} {(X_n)}_{0 \leq n \leq n_0} \\ 
{(Y_n)}_{0 \leq n \leq n_0}
\end{smallmatrix}\right.$.
\end{lemme}

\begin{proof}
Pour éviter des notations trop lourdes, nous écrivons la preuve pour $n_0=2$. 
Nous notons $(\FF'_0, \FF'_1, \FF'_2)$ la filtration engendrée par $(X'_0, X'_1, X'_2)$, 
et $(\FF''_0, \FF''_1, \FF''_2)$ la filtration engendrée par $(X''_0, X''_1, X''_2)$.

Sans restreindre la situation, on peut supposer que sur l'espace probabilisé de 
$\left\{\begin{smallmatrix} (X_0, X_1, X_2) \\ 
(Y_0, Y_1, Y_2)
\end{smallmatrix}\right.$, on a :
\begin{itemize}
\item $Y_0 = f_0(X_0, U_0)$, $U_0 \indep X_0$,
\item $Y_1 = f_1\bigl((X_0, Y_0, X_1), U_1\bigr)$, $U_1 \indep (X_0, U_0, X_1)$
\item $Y_2 = f_2\bigl((X_0, Y_0, X_1, Y_1, X_2), U_2\bigr)$, $U_2 \indep (X_0, U_0, X_1, U_1, X_2)$
\end{itemize} 

Après un grossissement éventuel, on peut supposer qu'on a, pour chaque $i\in\{0,1,2\}$, 
deux copies $U'_i$, $U''_i$  
de $U_i$ indépendantes de $\FF'_2\vee \FF''_2$, les $U'_i$ et $U''_j$ indépendantes entre elles. 
On pose :
\begin{itemize}
\item $Y'_0 = f_0(X'_0, U'_0)$,
\item $Y''_0 = f_0(X''_0, U''_0)$, 
\end{itemize}
et  $\HH_0 = \sigma(X'_0, X''_0) \indvee \sigma(U'_0, U''_0) \supset \sigma(X'_0, Y'_0, X''_0, Y''_0)$. 
Il est ainsi clair que $\left(\begin{smallmatrix}
X'_0 \\ Y'_0 \end{smallmatrix}\right)$ et 
$\left(\begin{smallmatrix}
X''_0 \\ Y''_0 \end{smallmatrix}\right)$ sont deux copies de 
$\left(\begin{smallmatrix}
X_0 \\ Y_0 \end{smallmatrix}\right)$ et on a clairement 
\begin{equation}\label{eq:quadricoimm1}
\LL(X'_1 \given \HH_0) = \LL(X'_1 \given X'_0, X''_0) = \LL(X'_1 \given X'_0)
\end{equation}
Posons maintenant :
\begin{itemize}
\item $Y'_1= f_1\bigl((X'_0, Y'_0, X'_1), U'_1\bigr)$,
\item $Y''_1 = f_1\bigl((X''_0, Y''_0, X''_1), U''_1\bigr)$.
\end{itemize}
Il est ainsi clair que $\left(\begin{smallmatrix}
X'_0, X'_1 \\ Y'_0, Y'_1 \end{smallmatrix}\right)$ et 
$\left(\begin{smallmatrix}
X''_0, X''_1 \\ Y''_0, Y''_1 \end{smallmatrix}\right)$ sont deux copies de 
$\left(\begin{smallmatrix}
X_0, X_1 \\ Y_0, Y_1 \end{smallmatrix}\right)$. 
Vérifions la propriété de synchronisation à $n=1$. On a clairement 
$$
\LL(Y'_1 \given \HH_0, X'_1) = \LL(Y'_1 \given X'_0, Y'_0, X'_1) 
$$
et grâce à~\eqref{eq:quadricoimm1} on obtient 
$$
\LL(Y'_1 \given \HH_0) = \LL(Y'_1 \given X'_0, Y'_0).  
$$
Notons $\HH_1 = \HH_0 \indvee \sigma(U'_1, U''_1)$. On a clairement 
\begin{equation}\label{eq:quadricoimm2}
\LL(X'_2 \given \HH_1) = \LL(X'_2 \given \FF'_1\vee\FF''_1) = \LL(X'_2 \given \FF'_1)
\end{equation}
On pose enfin 
\begin{itemize}
\item $Y'_2 = f_2\bigl((X'_0, Y'_0, X'_1, Y'_1, X'_2), U'_2\bigr)$,
\item $Y''_2 = f_2\bigl((X''_0, Y''_0, X''_1, Y''_1, X''_2), U''_2\bigr)$.
\end{itemize} 
Il est ainsi clair que $\left(\begin{smallmatrix}
X'_0, X'_1, X'_2 \\ Y'_0, Y'_1, Y'_2 \end{smallmatrix}\right)$ et 
$\left(\begin{smallmatrix}
X''_0, X''_1, X''_2 \\ Y''_0, Y''_1,Y''_2 \end{smallmatrix}\right)$ sont deux copies de 
$\left(\begin{smallmatrix}
X_0, X_1, X_2 \\ Y_0, Y_1, Y_2 \end{smallmatrix}\right)$. 
Vérifions la propriété de synchronisation à $n=1$. On a clairement 
$$
\LL(Y'_2 \given \HH_1, X'_2) = \LL(Y'_1 \given \FF'_1, Y'_0, Y'_1, X'_2) 
$$
et grâce à~\eqref{eq:quadricoimm2} on obtient 
$$
\LL(Y'_2 \given \HH_1) = \LL(Y'_2 \given \FF'_1, Y'_0, Y'_1) = \LL(Y'_2 \given Y'_0, Y'_1).  
$$
\end{proof}
\end{appendices}

%\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{thebibliography}{99.}

\bibitem{JLR} 
\'E.~Janvresse, S.~Laurent, T.~de la Rue: 
Standardness of monotonic Markov filtrations. 
	arXiv:1501.02166 (2015). 
To appear in: Markov Processes and Related Fields. 


\bibitem{LauTeoriya}  
 Laurent, S.: 
On Vershikian and I-cosy random variables and filtrations.
Teoriya Veroyatnostei i ee Primeneniya 55 (2010), 104--132. 
Also published in: Theory Probab. Appl. 55 (2011), 54--76.


\bibitem{LauXLV}
Laurent, S.: 
Vershik's Intermediate Level Standardness Criterion and the Scale of an Automorphism. 
S\'eminaire de Probabilit\'es XLV,
Springer Lecture Notes in Mathematics 2078,
123--139 (2013).

\bibitem{LauEntropy}
Laurent, S.: 
Uniform entropy scalings of filtrations. \\
\verb+https://hal.archives-ouvertes.fr/hal-01006337+ 


\bibitem{thescale} 
Vershik, A.M.: 
Four definitions of the scale of an automorphism. 
Funktsional'nyi Analiz i Ego Prilozheniya, 7:3, 
1--17 (1973). 
English translation:    
Functional Analysis and Its Applications, 7:3, 169--181 (1973)



\end{thebibliography}


\end{document}